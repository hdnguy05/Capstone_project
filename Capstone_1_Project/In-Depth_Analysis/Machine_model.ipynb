{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-Depth Analysis: Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import python libarary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from itertools import product\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_1 = pd.read_csv('data/sales_train.csv')\n",
    "df_test = pd.read_csv('data/test.csv', index_col = 'ID')\n",
    "df_item_1 = pd.read_csv('data/items.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_2 = df_train_1[((df_train_1.item_cnt_day > 0 ) & (df_train_1.item_cnt_day < 1000))]\n",
    "df_train_2 = df_train_2[df_train_2.item_price > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.merge(df_train_2, df_item_1, how = 'left')\n",
    "df_train = df_train.drop('item_name', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the data frame from the sale_traing file\n",
    "#Groupby the  shop_id and item_id, date_block_num\n",
    "temp_data = df_train.groupby(['shop_id','item_id']).agg({'item_cnt_day':'sum'})\n",
    "temp_data = temp_data.reset_index()\n",
    "temp_data['train_or_test'] = 1 #set as train set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_cat = df_train.groupby(['shop_id','item_id','item_category_id']).sum().reset_index()\n",
    "temp_cat = temp_cat[['shop_id','item_id','item_category_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.merge(df_test, temp_cat, how = 'left', on = ['shop_id','item_id'])\n",
    "df_test.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge Category_id to data frame\n",
    "temp_data = pd.merge(temp_data, temp_cat, how = 'left', on = ['shop_id', 'item_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the item_id of test set in training set\n",
    "test_item_id = df_test.item_id.unique()\n",
    "temp_data = temp_data[~temp_data['item_id'].isin(test_item_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#### Double checking if the item_id in test set still in train set \n",
    "x = temp_data.item_id.unique()\n",
    "y = df_test.item_id.unique()\n",
    "count = 0\n",
    "for i in x:\n",
    "    if i in y:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the date block number for df_test = 34\n",
    "#df_test['date_block_num'] = 34\n",
    "df_test['train_or_test'] = 0 #set as a test set\n",
    "df_test['item_cnt_day'] = 0\n",
    "#Then add the data to the df_temp_1\n",
    "df_train_test = pd.concat([temp_data, df_test], ignore_index= True, sort = False, keys = ['shop_id','item_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_test = df_train_test[['train_or_test','shop_id','item_id','item_category_id','item_cnt_day']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the feature for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the average of item_cnt_day for shop_id and date_block_num\n",
    "temp = df_train.groupby(['shop_id']).agg({'item_cnt_day':['mean']})\n",
    "temp.columns = ['shop_avg_item_cnt']\n",
    "temp = temp.reset_index()\n",
    "#Merge the feature above to the data\n",
    "df_train_test = pd.merge(df_train_test, temp, how = 'left', on = ['shop_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the average of item_cnt_day for date_block_num\n",
    "temp = df_train.groupby(['item_id']).agg({'item_cnt_day':['mean']})\n",
    "temp.columns = ['avg_item_cnt']\n",
    "temp = temp.reset_index()\n",
    "#Merge the feature above to the data\n",
    "df_train_test = pd.merge(df_train_test, temp, how = 'left', on = 'item_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the average of item_cnt_day for date_block_num\n",
    "temp = df_train.groupby(['item_category_id']).agg({'item_cnt_day':['mean']})\n",
    "temp.columns = ['avg_item_cnt_each_cat']\n",
    "temp = temp.reset_index()\n",
    "#Merge the feature above to the data\n",
    "df_train_test = pd.merge(df_train_test, temp, how = 'left', on = 'item_category_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the average of item_cnt_day for date_block_num, category_id\n",
    "\n",
    "temp = df_train.groupby(['item_category_id','item_id']).agg({'item_cnt_day':['mean']})\n",
    "temp.columns = ['cat_item_avg_item_cnt']\n",
    "temp = temp.reset_index()\n",
    "#Merge the feature above to the data\n",
    "df_train_test = pd.merge(df_train_test, temp, how = 'left', on = ['item_category_id','item_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the average price for each item by each shop_id and item_id\n",
    "temp_data_1 = df_train.groupby(['shop_id']).agg({'item_price':['mean']})\n",
    "temp_data_1.columns = ['avg_price_ofshop']\n",
    "temp_data_1 = temp_data_1.reset_index()\n",
    "\n",
    "df_train_test = pd.merge(df_train_test, temp_data_1, how = 'left', on = ['shop_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the average price for each item by each shop_id and item_id\n",
    "temp_data_1 = df_train.groupby(['shop_id','item_id']).agg({'item_price':['mean']})\n",
    "temp_data_1.columns = ['avg_price_each_item_ofshop']\n",
    "temp_data_1 = temp_data_1.reset_index()\n",
    "\n",
    "df_train_test = pd.merge(df_train_test, temp_data_1, how = 'left', on = ['shop_id','item_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the average price for each item by each shop_id and item_id\n",
    "temp_data_1 = df_train.groupby(['item_category_id','item_id']).agg({'item_price':['mean']})\n",
    "temp_data_1.columns = ['avg_price_each_item_cat']\n",
    "temp_data_1 = temp_data_1.reset_index()\n",
    "\n",
    "df_train_test = pd.merge(df_train_test, temp_data_1, how = 'left', on = ['item_category_id','item_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the average price for each item by each shop_id and item_id\n",
    "temp_data_1 = df_train.groupby(['item_id']).agg({'item_price':['min','max','mean']})\n",
    "temp_data_1.columns = ['min_price_each_item','max_price_each_item', 'mean_price_each_item']\n",
    "temp_data_1 = temp_data_1.reset_index()\n",
    "\n",
    "df_train_test = pd.merge(df_train_test, temp_data_1, how = 'left', on = ['item_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_or_test</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>item_cnt_day</th>\n",
       "      <th>shop_avg_item_cnt</th>\n",
       "      <th>avg_item_cnt</th>\n",
       "      <th>avg_item_cnt_each_cat</th>\n",
       "      <th>cat_item_avg_item_cnt</th>\n",
       "      <th>avg_price_ofshop</th>\n",
       "      <th>avg_price_each_item_ofshop</th>\n",
       "      <th>avg_price_each_item_cat</th>\n",
       "      <th>min_price_each_item</th>\n",
       "      <th>max_price_each_item</th>\n",
       "      <th>mean_price_each_item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>40.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.187481</td>\n",
       "      <td>1.233333</td>\n",
       "      <td>1.125806</td>\n",
       "      <td>1.233333</td>\n",
       "      <td>563.444151</td>\n",
       "      <td>247.0</td>\n",
       "      <td>375.828056</td>\n",
       "      <td>148.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>375.828056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.187481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.063038</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>563.444151</td>\n",
       "      <td>357.0</td>\n",
       "      <td>183.012195</td>\n",
       "      <td>58.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>183.012195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.187481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.009961</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>563.444151</td>\n",
       "      <td>127.0</td>\n",
       "      <td>245.138298</td>\n",
       "      <td>127.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>245.138298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_or_test  shop_id  item_id  item_category_id  item_cnt_day  \\\n",
       "0              1        0       35              40.0          15.0   \n",
       "1              1        0       36              37.0           1.0   \n",
       "2              1        0       40              57.0           1.0   \n",
       "\n",
       "   shop_avg_item_cnt  avg_item_cnt  avg_item_cnt_each_cat  \\\n",
       "0           1.187481      1.233333               1.125806   \n",
       "1           1.187481      1.000000               1.063038   \n",
       "2           1.187481      1.000000               1.009961   \n",
       "\n",
       "   cat_item_avg_item_cnt  avg_price_ofshop  avg_price_each_item_ofshop  \\\n",
       "0               1.233333        563.444151                       247.0   \n",
       "1               1.000000        563.444151                       357.0   \n",
       "2               1.000000        563.444151                       127.0   \n",
       "\n",
       "   avg_price_each_item_cat  min_price_each_item  max_price_each_item  \\\n",
       "0               375.828056                148.0                399.0   \n",
       "1               183.012195                 58.0                549.0   \n",
       "2               245.138298                127.0                249.0   \n",
       "\n",
       "   mean_price_each_item  \n",
       "0            375.828056  \n",
       "1            183.012195  \n",
       "2            245.138298  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>train_or_test</td>\n",
       "      <td>504098.0</td>\n",
       "      <td>0.575083</td>\n",
       "      <td>0.494331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>shop_id</td>\n",
       "      <td>504098.0</td>\n",
       "      <td>31.509905</td>\n",
       "      <td>17.236922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>59.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>item_id</td>\n",
       "      <td>504098.0</td>\n",
       "      <td>11423.812642</td>\n",
       "      <td>6175.751291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6183.000000</td>\n",
       "      <td>11648.000000</td>\n",
       "      <td>16587.000000</td>\n",
       "      <td>22169.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>item_category_id</td>\n",
       "      <td>504098.0</td>\n",
       "      <td>33.814760</td>\n",
       "      <td>21.795979</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>83.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>item_cnt_day</td>\n",
       "      <td>504098.0</td>\n",
       "      <td>3.429962</td>\n",
       "      <td>12.681862</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1704.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>shop_avg_item_cnt</td>\n",
       "      <td>504098.0</td>\n",
       "      <td>1.232275</td>\n",
       "      <td>0.200483</td>\n",
       "      <td>1.057546</td>\n",
       "      <td>1.156484</td>\n",
       "      <td>1.185057</td>\n",
       "      <td>1.261944</td>\n",
       "      <td>4.240983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>avg_item_cnt</td>\n",
       "      <td>488852.0</td>\n",
       "      <td>1.095128</td>\n",
       "      <td>0.527419</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.014870</td>\n",
       "      <td>1.069767</td>\n",
       "      <td>65.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>avg_item_cnt_each_cat</td>\n",
       "      <td>504098.0</td>\n",
       "      <td>1.107126</td>\n",
       "      <td>0.173733</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.029260</td>\n",
       "      <td>1.063038</td>\n",
       "      <td>1.125806</td>\n",
       "      <td>7.329770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cat_item_avg_item_cnt</td>\n",
       "      <td>401302.0</td>\n",
       "      <td>1.081952</td>\n",
       "      <td>0.328331</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.016129</td>\n",
       "      <td>1.068584</td>\n",
       "      <td>65.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>avg_price_ofshop</td>\n",
       "      <td>504098.0</td>\n",
       "      <td>921.241079</td>\n",
       "      <td>179.074771</td>\n",
       "      <td>299.237067</td>\n",
       "      <td>834.664881</td>\n",
       "      <td>917.856259</td>\n",
       "      <td>973.275624</td>\n",
       "      <td>1458.766652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>avg_price_each_item_ofshop</td>\n",
       "      <td>401302.0</td>\n",
       "      <td>795.310173</td>\n",
       "      <td>1793.346292</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>349.000000</td>\n",
       "      <td>787.648750</td>\n",
       "      <td>307980.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>avg_price_each_item_cat</td>\n",
       "      <td>401302.0</td>\n",
       "      <td>800.564176</td>\n",
       "      <td>1789.948950</td>\n",
       "      <td>4.914877</td>\n",
       "      <td>199.233509</td>\n",
       "      <td>344.892187</td>\n",
       "      <td>791.314125</td>\n",
       "      <td>307980.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min_price_each_item</td>\n",
       "      <td>488852.0</td>\n",
       "      <td>578.803540</td>\n",
       "      <td>1553.195876</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>530.000000</td>\n",
       "      <td>307980.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max_price_each_item</td>\n",
       "      <td>488852.0</td>\n",
       "      <td>995.165855</td>\n",
       "      <td>2184.790677</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>399.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>307980.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean_price_each_item</td>\n",
       "      <td>488852.0</td>\n",
       "      <td>847.228567</td>\n",
       "      <td>1849.119334</td>\n",
       "      <td>4.914877</td>\n",
       "      <td>211.959517</td>\n",
       "      <td>361.761905</td>\n",
       "      <td>888.156627</td>\n",
       "      <td>307980.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               count          mean          std         min  \\\n",
       "train_or_test               504098.0      0.575083     0.494331    0.000000   \n",
       "shop_id                     504098.0     31.509905    17.236922    0.000000   \n",
       "item_id                     504098.0  11423.812642  6175.751291    0.000000   \n",
       "item_category_id            504098.0     33.814760    21.795979    0.000000   \n",
       "item_cnt_day                504098.0      3.429962    12.681862    0.000000   \n",
       "shop_avg_item_cnt           504098.0      1.232275     0.200483    1.057546   \n",
       "avg_item_cnt                488852.0      1.095128     0.527419    1.000000   \n",
       "avg_item_cnt_each_cat       504098.0      1.107126     0.173733    1.000000   \n",
       "cat_item_avg_item_cnt       401302.0      1.081952     0.328331    1.000000   \n",
       "avg_price_ofshop            504098.0    921.241079   179.074771  299.237067   \n",
       "avg_price_each_item_ofshop  401302.0    795.310173  1793.346292    0.090000   \n",
       "avg_price_each_item_cat     401302.0    800.564176  1789.948950    4.914877   \n",
       "min_price_each_item         488852.0    578.803540  1553.195876    0.070000   \n",
       "max_price_each_item         488852.0    995.165855  2184.790677    5.000000   \n",
       "mean_price_each_item        488852.0    847.228567  1849.119334    4.914877   \n",
       "\n",
       "                                    25%           50%           75%  \\\n",
       "train_or_test                  0.000000      1.000000      1.000000   \n",
       "shop_id                       18.000000     31.000000     47.000000   \n",
       "item_id                     6183.000000  11648.000000  16587.000000   \n",
       "item_category_id              19.000000     40.000000     55.000000   \n",
       "item_cnt_day                   0.000000      1.000000      3.000000   \n",
       "shop_avg_item_cnt              1.156484      1.185057      1.261944   \n",
       "avg_item_cnt                   1.000000      1.014870      1.069767   \n",
       "avg_item_cnt_each_cat          1.029260      1.063038      1.125806   \n",
       "cat_item_avg_item_cnt          1.000000      1.016129      1.068584   \n",
       "avg_price_ofshop             834.664881    917.856259    973.275624   \n",
       "avg_price_each_item_ofshop   199.000000    349.000000    787.648750   \n",
       "avg_price_each_item_cat      199.233509    344.892187    791.314125   \n",
       "min_price_each_item           98.000000    215.000000    530.000000   \n",
       "max_price_each_item          249.000000    399.000000    999.000000   \n",
       "mean_price_each_item         211.959517    361.761905    888.156627   \n",
       "\n",
       "                                      max  \n",
       "train_or_test                    1.000000  \n",
       "shop_id                         59.000000  \n",
       "item_id                      22169.000000  \n",
       "item_category_id                83.000000  \n",
       "item_cnt_day                  1704.000000  \n",
       "shop_avg_item_cnt                4.240983  \n",
       "avg_item_cnt                    65.473684  \n",
       "avg_item_cnt_each_cat            7.329770  \n",
       "cat_item_avg_item_cnt           65.473684  \n",
       "avg_price_ofshop              1458.766652  \n",
       "avg_price_each_item_ofshop  307980.000000  \n",
       "avg_price_each_item_cat     307980.000000  \n",
       "min_price_each_item         307980.000000  \n",
       "max_price_each_item         307980.000000  \n",
       "mean_price_each_item        307980.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_test.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_test.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('train_or_test', 0),\n",
       " ('shop_id', 0),\n",
       " ('item_id', 0),\n",
       " ('item_category_id', 0),\n",
       " ('item_cnt_day', 0),\n",
       " ('shop_avg_item_cnt', 0),\n",
       " ('avg_item_cnt', 0),\n",
       " ('avg_item_cnt_each_cat', 0),\n",
       " ('cat_item_avg_item_cnt', 0),\n",
       " ('avg_price_ofshop', 0),\n",
       " ('avg_price_each_item_ofshop', 0),\n",
       " ('avg_price_each_item_cat', 0),\n",
       " ('min_price_each_item', 0),\n",
       " ('max_price_each_item', 0),\n",
       " ('mean_price_each_item', 0)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = list(df_train_test.isnull().sum().sort_values(ascending = True).items())\n",
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test_1.loc[:,'normalized_price'] = (df_test_1['item_price'] - df_test_1['item_price'].min()) / (df_test_1['item_price'].max() - df_test_1['item_price'].min())\n",
    "#df_test_1.loc[:,'standardized_price'] = (df_test_1['item_price'] - df_test_1['item_price'].mean()) / df_test_1['item_price'].std()\n",
    "#df_test_1.loc[:,'price_bin_round'] = np.array(np.floor(np.array(df_test_1['item_price']) / 100.))\n",
    "#df_test_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/auto_examples/compose/plot_transformed_target.html#sphx-glr-auto-examples-compose-plot-transformed-target-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['train_or_test', 'shop_id', 'item_id', 'item_category_id',\n",
       "       'item_cnt_day', 'shop_avg_item_cnt', 'avg_item_cnt',\n",
       "       'avg_item_cnt_each_cat', 'cat_item_avg_item_cnt', 'avg_price_ofshop',\n",
       "       'avg_price_each_item_ofshop', 'avg_price_each_item_cat',\n",
       "       'min_price_each_item', 'max_price_each_item', 'mean_price_each_item'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the feature  to the np.log\n",
    "\n",
    "col_name = ['item_cnt_day', 'shop_avg_item_cnt', 'avg_item_cnt',\n",
    "       'avg_item_cnt_each_cat', 'cat_item_avg_item_cnt', 'avg_price_ofshop',\n",
    "       'avg_price_each_item_ofshop', 'avg_price_each_item_cat',\n",
    "       'min_price_each_item', 'max_price_each_item', 'mean_price_each_item']\n",
    "#from sklearn.preprocessing import QuantileTransformer\n",
    "#qt = QuantileTransformer(n_quantiles=10, random_state=42)\n",
    "for i in col_name:\n",
    "    df_train_test[i] = df_train_test[i].apply(np.log1p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>train_or_test</td>\n",
       "      <td>504098.0</td>\n",
       "      <td>0.575083</td>\n",
       "      <td>0.494331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>shop_id</td>\n",
       "      <td>504098.0</td>\n",
       "      <td>31.509905</td>\n",
       "      <td>17.236922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>59.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>item_id</td>\n",
       "      <td>504098.0</td>\n",
       "      <td>11423.812642</td>\n",
       "      <td>6175.751291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6183.000000</td>\n",
       "      <td>11648.000000</td>\n",
       "      <td>16587.000000</td>\n",
       "      <td>22169.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>item_category_id</td>\n",
       "      <td>504098.0</td>\n",
       "      <td>33.814760</td>\n",
       "      <td>21.795979</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>83.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>item_cnt_day</td>\n",
       "      <td>504098.0</td>\n",
       "      <td>0.826628</td>\n",
       "      <td>0.946875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>7.441320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>shop_avg_item_cnt</td>\n",
       "      <td>504098.0</td>\n",
       "      <td>0.800057</td>\n",
       "      <td>0.071883</td>\n",
       "      <td>0.721514</td>\n",
       "      <td>0.768479</td>\n",
       "      <td>0.781642</td>\n",
       "      <td>0.816225</td>\n",
       "      <td>1.656509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>avg_item_cnt</td>\n",
       "      <td>504098.0</td>\n",
       "      <td>0.709629</td>\n",
       "      <td>0.160044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.699662</td>\n",
       "      <td>0.726103</td>\n",
       "      <td>4.196806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>avg_item_cnt_each_cat</td>\n",
       "      <td>504098.0</td>\n",
       "      <td>0.743072</td>\n",
       "      <td>0.062378</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.707671</td>\n",
       "      <td>0.724180</td>\n",
       "      <td>0.754151</td>\n",
       "      <td>2.119836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cat_item_avg_item_cnt</td>\n",
       "      <td>504098.0</td>\n",
       "      <td>0.580026</td>\n",
       "      <td>0.303157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.694888</td>\n",
       "      <td>0.717245</td>\n",
       "      <td>4.196806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>avg_price_ofshop</td>\n",
       "      <td>504098.0</td>\n",
       "      <td>6.806619</td>\n",
       "      <td>0.207834</td>\n",
       "      <td>5.704572</td>\n",
       "      <td>6.728228</td>\n",
       "      <td>6.823130</td>\n",
       "      <td>6.881694</td>\n",
       "      <td>7.286032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>avg_price_each_item_ofshop</td>\n",
       "      <td>504098.0</td>\n",
       "      <td>4.791982</td>\n",
       "      <td>2.594140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.736848</td>\n",
       "      <td>5.700444</td>\n",
       "      <td>6.351698</td>\n",
       "      <td>12.637793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>avg_price_each_item_cat</td>\n",
       "      <td>504098.0</td>\n",
       "      <td>4.814653</td>\n",
       "      <td>2.592130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.894738</td>\n",
       "      <td>5.671358</td>\n",
       "      <td>6.372791</td>\n",
       "      <td>12.637793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min_price_each_item</td>\n",
       "      <td>504098.0</td>\n",
       "      <td>5.303482</td>\n",
       "      <td>1.562383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.522984</td>\n",
       "      <td>5.306583</td>\n",
       "      <td>6.216606</td>\n",
       "      <td>12.637793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max_price_each_item</td>\n",
       "      <td>504098.0</td>\n",
       "      <td>6.074190</td>\n",
       "      <td>1.464077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.521461</td>\n",
       "      <td>5.991465</td>\n",
       "      <td>6.907755</td>\n",
       "      <td>12.637793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean_price_each_item</td>\n",
       "      <td>504098.0</td>\n",
       "      <td>5.919628</td>\n",
       "      <td>1.441543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.294690</td>\n",
       "      <td>5.855468</td>\n",
       "      <td>6.753110</td>\n",
       "      <td>12.637793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               count          mean          std       min  \\\n",
       "train_or_test               504098.0      0.575083     0.494331  0.000000   \n",
       "shop_id                     504098.0     31.509905    17.236922  0.000000   \n",
       "item_id                     504098.0  11423.812642  6175.751291  0.000000   \n",
       "item_category_id            504098.0     33.814760    21.795979  0.000000   \n",
       "item_cnt_day                504098.0      0.826628     0.946875  0.000000   \n",
       "shop_avg_item_cnt           504098.0      0.800057     0.071883  0.721514   \n",
       "avg_item_cnt                504098.0      0.709629     0.160044  0.000000   \n",
       "avg_item_cnt_each_cat       504098.0      0.743072     0.062378  0.693147   \n",
       "cat_item_avg_item_cnt       504098.0      0.580026     0.303157  0.000000   \n",
       "avg_price_ofshop            504098.0      6.806619     0.207834  5.704572   \n",
       "avg_price_each_item_ofshop  504098.0      4.791982     2.594140  0.000000   \n",
       "avg_price_each_item_cat     504098.0      4.814653     2.592130  0.000000   \n",
       "min_price_each_item         504098.0      5.303482     1.562383  0.000000   \n",
       "max_price_each_item         504098.0      6.074190     1.464077  0.000000   \n",
       "mean_price_each_item        504098.0      5.919628     1.441543  0.000000   \n",
       "\n",
       "                                    25%           50%           75%  \\\n",
       "train_or_test                  0.000000      1.000000      1.000000   \n",
       "shop_id                       18.000000     31.000000     47.000000   \n",
       "item_id                     6183.000000  11648.000000  16587.000000   \n",
       "item_category_id              19.000000     40.000000     55.000000   \n",
       "item_cnt_day                   0.000000      0.693147      1.386294   \n",
       "shop_avg_item_cnt              0.768479      0.781642      0.816225   \n",
       "avg_item_cnt                   0.693147      0.699662      0.726103   \n",
       "avg_item_cnt_each_cat          0.707671      0.724180      0.754151   \n",
       "cat_item_avg_item_cnt          0.693147      0.694888      0.717245   \n",
       "avg_price_ofshop               6.728228      6.823130      6.881694   \n",
       "avg_price_each_item_ofshop     4.736848      5.700444      6.351698   \n",
       "avg_price_each_item_cat        4.894738      5.671358      6.372791   \n",
       "min_price_each_item            4.522984      5.306583      6.216606   \n",
       "max_price_each_item            5.521461      5.991465      6.907755   \n",
       "mean_price_each_item           5.294690      5.855468      6.753110   \n",
       "\n",
       "                                     max  \n",
       "train_or_test                   1.000000  \n",
       "shop_id                        59.000000  \n",
       "item_id                     22169.000000  \n",
       "item_category_id               83.000000  \n",
       "item_cnt_day                    7.441320  \n",
       "shop_avg_item_cnt               1.656509  \n",
       "avg_item_cnt                    4.196806  \n",
       "avg_item_cnt_each_cat           2.119836  \n",
       "cat_item_avg_item_cnt           4.196806  \n",
       "avg_price_ofshop                7.286032  \n",
       "avg_price_each_item_ofshop     12.637793  \n",
       "avg_price_each_item_cat        12.637793  \n",
       "min_price_each_item            12.637793  \n",
       "max_price_each_item            12.637793  \n",
       "mean_price_each_item           12.637793  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_test.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data For Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperata the Train set\n",
    "data = df_train_test[df_train_test['train_or_test'] == 1]\n",
    "data = data.drop(['train_or_test','item_category_id','shop_id','item_id'], axis =1)\n",
    "#submit file predict\n",
    "submit = df_train_test[df_train_test['train_or_test'] == 0]\n",
    "submit = submit.drop(['train_or_test','item_category_id','shop_id','item_id'],axis= 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Target 'y' and feature 'X' for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Target y and feature X base on the train set\n",
    "y = data['item_cnt_day']\n",
    "X = data.drop('item_cnt_day', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data to traing set and test set base on the train set to train model\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(202928, 202928)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Xtrain), len(ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-NN Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import sklearn for model\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection the importance feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'n_neighbors': 5}, 0.5389903524559968)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Hyperparameter tunning ###\n",
    "######### FIND BEST n_neighbors ###############\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'n_neighbors': np.arange(5,6,1)}\n",
    "knn = KNeighborsRegressor()\n",
    "knn_cv = GridSearchCV(knn, param_grid, cv = 5)\n",
    "knn_cv.fit(Xtrain,ytrain)\n",
    "knn_cv.best_params_ , knn_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the labels of the test data\n",
    "y_pred = knn_cv.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking score test and predict\n",
    "test_accuray = knn_cv.score(Xtest, ytest)\n",
    "train_accuray = knn_cv.score(Xtrain, ytrain)\n",
    "rmse = np.sqrt(mean_squared_error(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 of model:  0.5507134233545816\n",
      "RMSE of model:  0.5513823603660406\n"
     ]
    }
   ],
   "source": [
    "print('R^2 of model: ',test_accuray)\n",
    "print('RMSE of model: ', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7080143218064845"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_accuray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importance feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf = RandomForestRegressor()\n",
    "#rf.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features_name = data.drop('item_cnt_day', axis = 1).columns\n",
    "#Score = rf.feature_importances_\n",
    "#no_name = zip(features_name, Score)\n",
    "#temp_f = pd.DataFrame(no_name,  columns = ['name', 'score'])\n",
    "#temp_f = temp_f.sort_values('score', ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select top 3 feature\n",
    "#col_name = temp_f.name.values[0:5]\n",
    "#col_name = ['avg_item_cnt', 'shop_cat_avg_item_cnt', 'mean_price_each_item',\n",
    " #      'min_price_each_item', 'shop_avg_item_cnt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xtrain_rf = Xtrain[col_name]\n",
    "#Xtest_rf = Xtest[col_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xtrain_rf = Xtrain_rf.values\n",
    "#ytrain_rf = ytrain.values\n",
    "#Xtest_rf = Xtest_rf.values\n",
    "#ytest_rf = ytest.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xtrain_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### end___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate the model\n",
    "rf = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Hyperparameter tunning ###\n",
    "###CHoice BEST PARAMETER ##\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 20, num = 5)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 5)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Instantiate the tunning parameter using RandomizeSearchCV\n",
    "rf_cv = RandomizedSearchCV(rf, random_grid, cv = 5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=RandomForestRegressor(bootstrap=True,\n",
       "                                                   ccp_alpha=0.0,\n",
       "                                                   criterion='mse',\n",
       "                                                   max_depth=None,\n",
       "                                                   max_features='auto',\n",
       "                                                   max_leaf_nodes=None,\n",
       "                                                   max_samples=None,\n",
       "                                                   min_impurity_decrease=0.0,\n",
       "                                                   min_impurity_split=None,\n",
       "                                                   min_samples_leaf=1,\n",
       "                                                   min_samples_split=2,\n",
       "                                                   min_weight_fraction_leaf=0.0,\n",
       "                                                   n_estimators=100,\n",
       "                                                   n_jobs=None, oob_score=Fals...\n",
       "                                                   warm_start=False),\n",
       "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 35, 60, 85, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [10, 12, 15, 17, 20]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cv.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'n_estimators': 20,\n",
       "  'min_samples_split': 5,\n",
       "  'min_samples_leaf': 1,\n",
       "  'max_features': 'sqrt',\n",
       "  'max_depth': None,\n",
       "  'bootstrap': False},\n",
       " 0.6780957584868701)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Get the best parameter and best score\n",
    "rf_cv.best_params_, rf_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the data\n",
    "y_pred_rf = rf_cv.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the R^2 and RMSE\n",
    "test_accuary_rf = rf_cv.score(Xtest, ytest)\n",
    "train_accuary_rf = rf_cv.score(Xtrain, ytrain)\n",
    "rmse_rf = np.sqrt(mean_squared_error(ytest, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 of model:  0.6815191048879072\n",
      "RMSE of model:  0.46422961156563797\n"
     ]
    }
   ],
   "source": [
    "print('R^2 of model: ',test_accuary_rf)\n",
    "print('RMSE of model: ', rmse_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xgboost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 2,\n",
    "          'learning_rate': 0.01, 'loss': 'ls'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
       "                          init=None, learning_rate=0.01, loss='ls', max_depth=4,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                          n_iter_no_change=None, presort='deprecated',\n",
       "                          random_state=None, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg = GradientBoostingRegressor(**params)\n",
    "xg.fit(Xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict \n",
    "y_pred_xg = xg.predict(Xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuary_xg = xg.score(Xtest, ytest)\n",
    "train_accuary_xg = xg.score(Xtrain, ytrain)\n",
    "rmse_xg = np.sqrt(mean_squared_error(ytest, y_pred_xg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 of model of test set:  0.47742190839230103\n",
      "RMSE of model:  0.5946572878853934\n",
      "R^2 train set:  0.4859775180855838\n"
     ]
    }
   ],
   "source": [
    "print('R^2 of model of test set: ',test_accuary_xg)\n",
    "print('RMSE of model: ', rmse_xg)\n",
    "print('R^2 train set: ', train_accuary_xg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Used feature engieering, to add more feature for modeling\n",
    "- Data have alot items was only 1 per day, so I used log transform to have better data\n",
    "- Also price is same, it crewed so I also use log trandform.\n",
    "- standardided and normilized both item_cnt_data and item_price\n",
    "\n",
    "- Overrall, that show random forest regression model have better R^2 score and RMSE score\n",
    "- We choice the random forest regression for our problem here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
